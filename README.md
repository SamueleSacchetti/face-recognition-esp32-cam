# Face recognition using ESP32-Cam 
ESP32-Cam is an edge device with low memory capacity and low computational performance. It can be used for many tasks such as automation, security and surveillance, and so on. 
In this job, we used the ESP32-Cam to perform real-time inference using a pre-trained face recognition model, handling the output with LEDs based on the result obtained.

## Failed steps before the success
  ### First Approach
We started with a "manual approach", performing a fine-tuning process on the MobileNetV2 model. The dataset used was composed of our faces and unknown people faces pictures. During the implementation (using Micropython as programming language and Thonny as IDE), we faced two main problems:
    1. the model we got was too big to save and run on the device;
    2. there is not a Tensorflow Lite library for Micropython.
    
This solution can be found [here](./python_customModel).

  ### Second Approach
After the experience with Micropython and Tensorflow Lite, we converted the .savedModel file into a byte array C so we could upload the model on the device in an easier way. After that the second problem we had in the first approach has been solved. However the first problem remained cause of the model's size.
So we found a "person detection" model provided by Tensorflow Lite. The model's output is a confidence score that says if a person is in front of the camera or not. In this second approach we used Arduino as IDE but the results obtained were not satistfying cause of the low accuracy of the results.

This second solution can be found [here](./tflite_arduino_person_detection).

  ### Final Approach: the success!
All these failures lowered our morale, but we learned a lot from the experiences. We decided to try another approach using the tool Edge Impulse. We rebuilt the dataset from scratch using Roboflow's tools. To avoid overfitting, we added more pictures and performed data augmentation. Then, we fine-tuned MobileNetv2 on Edge Impulse, which produced the model and automatically converted it to TensorFlowLite. After that, Edge Impulse generated the basic C code needed to run the model inference on the ESP32.

This final solution con be found [here](./arduino_edge_impulse).

## Inference of the face recognition model
We modified the code generated by Edge Impulse to suit our needs. Specifically, we configured the pins to connect the SD card and the camera. To manage the output and activate the appropriate LED, we added a confidence threshold. When the threshold is exceeded, the LED corresponding to the classification result is turned on, otherwise it is turned off.


## How to replicate the obtained results
Here's the steps to replicate the final result:

1. install and run Arduino IDE;
2. install "TensorflowLite_ESP32" library on Arduino IDE;
3. configure the camera depending on the used device. We used the "CAMERA_MODEL_WROVER_KIT" module. The provided camera configuration for ESP32 can be found [here](https://github.com/espressif/esp32-camera);
4. connect the device to the computer via USB;
5. check the right port and the device on Arduino IDE settings;
6. compile and run the [code](./arduino_edge_impulse/examples/esp32/esp32_camera_2024/esp32_camera_2024.ino).

As yuo can see in the source code, you can define the PIN where you can connect the different LEDs. Each led is "connected" to a specific class predicted by the model.

```C
#define PIN_BLUE 2
#define PIN_GREEN 15
#define PIN_RED 32
```

The model can be find [here](arduino_edge_impulse/src/tflite-model).
